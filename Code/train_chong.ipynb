{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import cv2\n",
    "\n",
    "from utils_logging import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choose between Recasens or GazeNet\n",
    "\n",
    "- Idea is you can just swap \n",
    "models.recasens, dataloader.recasens, training.train_recasens, etc...\n",
    "- with the following\n",
    "models.gazenet, dataloader.gazenet, training.train_gazenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from models.chong import ModelSpatial\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from dataloader.chong import GazeDataset, GooDataset\n",
    "from dataloader import chong_imutils\n",
    "from training.train_chong import train, test, GazeOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger will save the training and test errors to a .log file \n",
    "logger = setup_logger(name='first_logger',\n",
    "                      log_dir ='./logs/',\n",
    "                      log_file='train_chong_gooreal.log',\n",
    "                      log_format = '%(asctime)s %(levelname)s %(message)s',\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dataloaders\n",
    "- Choose between GazeDataset (Gazefollow dataset) or GooDataset (GooSynth/GooReal)\n",
    "- Set paths to image directories and pickle paths. For Gazefollow, images_dir and test_images_dir should be the same and both lead to the path containing the train and test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 172800\n",
      "Number of Images: 19200\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Synth\n",
    "batch_size=32\n",
    "workers=12\n",
    "\n",
    "images_dir = '/hdd/HENRI/goosynth/1person/GazeDatasets/'\n",
    "pickle_path = '/hdd/HENRI/goosynth/picklefiles/trainpickle2to19human.pickle'\n",
    "test_images_dir = '/hdd/HENRI/goosynth/test/'\n",
    "test_pickle_path = '/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for GOO-Real\n",
    "batch_size=4\n",
    "workers=12\n",
    "\n",
    "images_dir = '/home/shashimal/Desktop/FYPGaze/gooreal/finalrealdatasetImgsV2/'\n",
    "pickle_path = '/home/shashimal/Desktop/FYPGaze/gooreal/oneshotrealhumansNew.pickle'\n",
    "test_images_dir = '/home/shashimal/Desktop/FYPGaze/gooreal/finalrealdatasetImgsV2/'\n",
    "test_pickle_path = '/home/shashimal/Desktop/FYPGaze/gooreal/testrealhumansNew.pickle'\n",
    "\n",
    "train_set = GooDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders for GAZE\n",
    "\n",
    "batch_size=32\n",
    "workers=12\n",
    "testbatchsize=16\n",
    "\n",
    "images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/train_annotations.mat'\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GazeFollowData/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GazeFollowData/test_annotations.mat'\n",
    "\n",
    "train_set = GazeDataset(images_dir, pickle_path, 'train')\n",
    "train_data_loader = DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=16)\n",
    "\n",
    "test_set = GazeDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = DataLoader(test_set, batch_size=batch_size//2,\n",
    "                            shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Model and Set Training Hyperparameters\n",
    "- For Gazefollow, the model requires the alexnet_places365 pretrained model, provided here: https://urlzs.com/ytKK3\n",
    "- When resuming training, set to True and set the resume_path for the saved model.\n",
    "- Here, logging module is initialized (logger) to save training and testing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Constructing model\n",
      "==> Loading initial weights\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/s9y65ajzjz4thve/initial_weights_for_spatial_training.pt\n",
    "init_weights = 'initial_weights_for_spatial_training.pt'\n",
    "\n",
    "# Loads model\n",
    "print(\"==> Constructing model\")\n",
    "net = ModelSpatial()\n",
    "net.cuda()\n",
    "\n",
    "# Hyperparameters\n",
    "start_epoch = 0\n",
    "max_epoch = 5\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Initial weights chong\n",
    "print(\"==> Loading initial weights\")\n",
    "model_dict = net.state_dict()\n",
    "pretrained_dict = torch.load(init_weights)\n",
    "pretrained_dict = pretrained_dict['model']\n",
    "model_dict.update(pretrained_dict)\n",
    "net.load_state_dict(model_dict)\n",
    "\n",
    "# Initializes Optimizer\n",
    "gaze_opt = GazeOptimizer(net, learning_rate)\n",
    "optimizer = gaze_opt.getOptimizer(start_epoch)\n",
    "\n",
    "# Resuming Training\n",
    "resume_training = False\n",
    "resume_path = './saved_models/chong_goosynth/model_epoch25.pth.tar'\n",
    "if resume_training:\n",
    "    net, optimizer, _ = resume_checkpoint(net, optimizer,resume_path)\n",
    "    test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1073 [00:00<?, ?it/s]/home/shashimal/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  0%|          | 1/1073 [00:05<1:34:29,  5.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5348/3165974362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/GOO-GAZE2021/gazefollowing/training/train_chong.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(net, test_data_loader, logger, save_output)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0ml2_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mgaze_inside\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaze_inside\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0ml2_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze_inside\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# zero out loss when it's out-of-frame gaze case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0ml2_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze_inside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;31m# cross entropy loss for in vs out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the Model\n",
    "- Determine in which epochs do you want to save the model, as you might not want to save every epoch\n",
    "- Training and test errors can be accessed in the logs directory set up earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashimal/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "  0%|          | 0/613 [00:00<?, ?it/s]/home/shashimal/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      " 16%|█▌        | 99/613 [05:20<27:19,  3.19s/it]68.27586071014404\n",
      " 32%|███▏      | 199/613 [10:39<22:00,  3.19s/it]67.43212947845458\n",
      " 49%|████▉     | 299/613 [15:57<16:28,  3.15s/it]66.64984302520752\n",
      " 65%|██████▌   | 399/613 [19:25<07:24,  2.08s/it]66.35670455932618\n",
      " 81%|████████▏ | 499/613 [22:53<03:57,  2.08s/it]65.80953327178955\n",
      " 98%|█████████▊| 599/613 [26:20<00:28,  2.07s/it]65.7650089263916\n",
      "100%|██████████| 613/613 [26:49<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 99/613 [03:27<17:42,  2.07s/it]65.20166042327881\n",
      " 32%|███▏      | 199/613 [06:53<14:14,  2.06s/it]65.2870754623413\n",
      " 49%|████▉     | 299/613 [10:44<11:59,  2.29s/it]64.93747440338134\n",
      " 65%|██████▌   | 399/613 [14:33<08:03,  2.26s/it]65.3558052444458\n",
      " 81%|████████▏ | 499/613 [18:22<04:22,  2.30s/it]64.85508255004883\n",
      " 98%|█████████▊| 599/613 [22:08<00:28,  2.01s/it]64.382360496521\n",
      "100%|██████████| 613/613 [22:36<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 99/613 [03:21<17:17,  2.02s/it]64.03812389373779\n",
      " 32%|███▏      | 199/613 [06:43<13:53,  2.01s/it]64.13457027435302\n",
      " 49%|████▉     | 299/613 [10:06<10:31,  2.01s/it]63.584960823059085\n",
      " 65%|██████▌   | 399/613 [13:28<07:11,  2.02s/it]63.30810253143311\n",
      " 81%|████████▏ | 499/613 [16:49<03:49,  2.01s/it]63.34888717651367\n",
      " 98%|█████████▊| 599/613 [20:13<00:28,  2.01s/it]63.07262031555176\n",
      "100%|██████████| 613/613 [20:42<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 99/613 [03:23<17:12,  2.01s/it]62.31209442138672\n",
      " 32%|███▏      | 199/613 [06:43<13:01,  1.89s/it]63.033398094177244\n",
      " 49%|████▉     | 299/613 [09:51<09:50,  1.88s/it]63.33745651245117\n",
      " 65%|██████▌   | 399/613 [13:01<06:39,  1.87s/it]63.7181665802002\n",
      " 81%|████████▏ | 499/613 [16:07<03:32,  1.87s/it]62.06017261505127\n",
      " 98%|█████████▊| 599/613 [19:14<00:26,  1.87s/it]62.6815690612793\n",
      "100%|██████████| 613/613 [19:40<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "best_l2 = np.inf\n",
    "\n",
    "for epoch in range(1,5):\n",
    "\n",
    "    # Update optimizer\n",
    "    optimizer = gaze_opt.getOptimizer(epoch)\n",
    "\n",
    "    # Train model\n",
    "    print('training')\n",
    "    train(net, train_data_loader, optimizer, epoch, logger)\n",
    "\n",
    "    # Evaluate model\n",
    "    #scores = test(net, test_data_loader, logger)\n",
    "    \n",
    "    # Save model+optimizer with best L2 Scorehttp://localhost:8888/notebooks/train_chong.ipynb#\n",
    "    #if scores[1] < best_l2:\n",
    "    #    best_l2 = scores[1]\n",
    "    #    save_path = './saved_models/chong_gooreal_notrained/'\n",
    "    #    save_checkpoint(net, optimizer, 420, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1073 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6595/3165974362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/GOO-GAZE2021/gazefollowing/training/train_chong.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(net, test_data_loader, logger, save_output)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mval_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_face\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mval_gaze_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gaze_heatmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mval_gaze_heatmap_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_attmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_inout_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mval_gaze_heatmap_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gaze_heatmap_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'objects'"
     ]
    }
   ],
   "source": [
    "test(net, test_data_loader,logger, save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}